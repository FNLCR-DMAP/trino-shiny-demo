services:

  # PostgreSQL database for Hive Metastore
  postgres:
    image: postgres:15
    container_name: postgres
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive123
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - iceberg-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive -d metastore"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Hive Metastore (using PostgreSQL database)
  hive-metastore:
    image: apache/hive:4.0.0
    container_name: hive-metastore
    user: "0:0"
    environment:
      - SERVICE_NAME=metastore
      - IS_RESUME=false
      - DB_DRIVER=postgres
    ports:
      - "${HIVE_PORT:-9083}:9083"
    volumes:
      - ./hive-site.xml:/opt/hive/conf/hive-site.xml
      - ./warehouse:/data/warehouse
      - ./hive/lib/postgresql-42.6.0.jar:/opt/hive/lib/postgresql-42.6.0.jar
    networks:
      - iceberg-net
    depends_on:
      postgres:
        condition: service_healthy

  # Trino Coordinator
  trino:
    image: trinodb/trino:435
    container_name: trino
    user: "0:0"
    ports:
      - "${TRINO_PORT:-8083}:8080"
    volumes:
      - ./trino/etc:/etc/trino
      - ./trino/catalog:/etc/trino/catalog
      - ./warehouse:/data/warehouse
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    depends_on:
      - hive-metastore
    networks:
      - iceberg-net

  # Trino CLI (for easy access)
  trino-cli:
    image: trinodb/trino:435
    container_name: trino-cli
    entrypoint: ["/bin/bash", "-c", "sleep infinity"]
    depends_on:
      - trino
    networks:
      - iceberg-net

  # Apache Spark with Iceberg support for branching
  spark:
    image: apache/spark:3.5.0
    container_name: spark-iceberg
    user: "0:0"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=0.0.0.0
    ports:
      - "${SPARK_PORT:-8082}:8080"  # Spark UI (different from Trino)
      - "7077:7077"  # Spark Master
    volumes:
      - ./warehouse:/data/warehouse
      - ./scripts:/scripts
      - ./hive-site.xml:/opt/spark/conf/hive-site.xml
      - ./jars:/opt/spark/jars-local
    networks:
      - iceberg-net
    depends_on:
      - hive-metastore
    command:
      - bash
      - -c
      - |
        echo 'Copying Iceberg JAR from local mount...'
        if [ -f /opt/spark/jars-local/iceberg-spark-runtime-3.5_2.12-1.4.2.jar ]; then
          cp /opt/spark/jars-local/iceberg-spark-runtime-3.5_2.12-1.4.2.jar /opt/spark/jars/
          echo 'Iceberg JAR copied successfully'
        else
          echo 'WARNING: Iceberg JAR not found in mount!'
        fi
        ls -la /opt/spark/jars/iceberg* || echo 'JAR verification failed'
        echo 'Starting Spark Master...'
        /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host 0.0.0.0 --port 7077 --webui-port 8080 &
        echo 'Spark Master started, keeping container alive...'
        while true; do sleep 30; done

  # Shiny for Python Frontend
  shiny-app:
    build:
      context: ./shiny-app
      dockerfile: Dockerfile
    image: trino-shiny-app:latest
    container_name: shiny-app
    ports:
      - "${SHINY_PORT:-8000}:8000"
    depends_on:
      - trino
    networks:
      - iceberg-net
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - ./shiny-app/app.py:/app/app.py
      - ./shiny-app/shared:/app/shared

  # Deployment container for Posit Connect
  deploy-shiny:
    build:
      context: ./shiny-app
      dockerfile: Dockerfile.deploy
    image: trino-shiny-app-deploy:latest
    container_name: deploy-shiny
    networks:
      - iceberg-net
    environment:
      - PYTHONUNBUFFERED=1
      - RSCONNECT_HOME=/root/.rsconnect-python
    volumes:
      - ./shiny-app:/deploy
      - "${HOME}/Library/Application Support/rsconnect-python:/root/.rsconnect-python:ro"
    # The actual deploy command will be passed by make

volumes:
  postgres-data:

networks:
  iceberg-net:
    driver: bridge
